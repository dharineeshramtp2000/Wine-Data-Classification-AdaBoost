{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Male/Female Voice Predictor.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOb61VVLudNRx37HscTKxqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharineeshramtp2000/Wine-Data-Classification-AdaBoost/blob/master/Male_Female_Voice_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmeaUi3cXjJ6",
        "colab_type": "text"
      },
      "source": [
        "Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0gG7dpoXchH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1EEG2XqUH",
        "colab_type": "text"
      },
      "source": [
        "Importing the Dataset. Here we use the dataset from [ML Data](https://www.mldata.io/datasets/).\n",
        "![](https://www.goodfood.com.au/content/dam/images/h/1/5/t/q/e/image.related.wideLandscape.940x529.h17bz1.png/1541726361585.jpg)\n",
        "---\n",
        "\n",
        "Here we are going to determine the class of wine based on few independent variables.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tifsPeCMYo2u",
        "colab_type": "code",
        "outputId": "45b04568-c59e-4d78-9ba6-2d4453d1e891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "Dataset = pd.read_csv(\"wine_weka_dataset.csv\")\n",
        "X = Dataset.iloc[:,:-1].values\n",
        "y = Dataset.iloc[:,-1].values\n",
        "Dataset.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>Malic acid</th>\n",
              "      <th>Ash</th>\n",
              "      <th>Alcalinity of ash</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Total phenols</th>\n",
              "      <th>Flavanoids</th>\n",
              "      <th>Nonflavanoid phenols</th>\n",
              "      <th>Proanthocyanins</th>\n",
              "      <th>Color intensity</th>\n",
              "      <th>Hue</th>\n",
              "      <th>OD280/OD315 of diluted wines</th>\n",
              "      <th>Proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Alcohol  Malic acid  ...  OD280/OD315 of diluted wines      Proline\n",
              "count  178.000000  178.000000  ...                    178.000000   178.000000\n",
              "mean    13.000618    2.336348  ...                      2.611685   746.893258\n",
              "std      0.811827    1.117146  ...                      0.709990   314.907474\n",
              "min     11.030000    0.740000  ...                      1.270000   278.000000\n",
              "25%     12.362500    1.602500  ...                      1.937500   500.500000\n",
              "50%     13.050000    1.865000  ...                      2.780000   673.500000\n",
              "75%     13.677500    3.082500  ...                      3.170000   985.000000\n",
              "max     14.830000    5.800000  ...                      4.000000  1680.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMX-6lXTZsod",
        "colab_type": "text"
      },
      "source": [
        "Lets Feature Scale the independent variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erXFDhgeNSRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X = sc_X.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2CaoxRcZeMd",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset into training and testing and performing a good shuffle of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP83grDqZlOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.3, random_state =42, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E82SIY2PZmNj",
        "colab_type": "text"
      },
      "source": [
        "Now lets define our Adaboost Classifier.\n",
        "We know how trees work. We use these attributes in order to make the splits and finally make the prediction using the leaf values of the tree.\n",
        "Instead of using normal trees, lets define it using boosting algorithm(**here Adaboost**)\n",
        "\n",
        "![](https://www.frontiersin.org/files/Articles/284242/fnagi-09-00329-HTML/image_t/fnagi-09-00329-g001.gif)\n",
        "\n",
        "Feel free to use the [Documnetaton for Adaboost Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bLh52NbAxk",
        "colab_type": "code",
        "outputId": "adb4e781-ee07-4717-a548-8a7fca351573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "classifier = AdaBoostClassifier()\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=50, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2j8E0L4b78d",
        "colab_type": "text"
      },
      "source": [
        "Now lets predict with our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMBI0Utb_rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNpmUnI7N4m6",
        "colab_type": "text"
      },
      "source": [
        "Now lets evaluate the accuracy , F1 score and the Confusion Matrix in order to check how well our model is classifying new data\n",
        "\n",
        "---\n",
        "\n",
        "First lets see how model works with our tarining examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KYRW9ybOTBa",
        "colab_type": "code",
        "outputId": "8a786f28-871c-42c7-cd38-3a807c8fd7cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "acc_train = accuracy_score(y_train, classifier.predict(X_train))\n",
        "f1_train = f1_score(y_train, classifier.predict(X_train), average= 'weighted')\n",
        "\n",
        "print(\"Traing set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_train)\n",
        "print(\"F1 SCORE ---------------------->\",f1_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traing set results\n",
            "ACCURACY ----------------------> 0.9435483870967742\n",
            "F1 SCORE ----------------------> 0.9436949059289295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1M_725gOfEp",
        "colab_type": "text"
      },
      "source": [
        "Now lets see how well is our model. So now lets evaluate with our test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot3d3ndRN27r",
        "colab_type": "code",
        "outputId": "976bb678-6c56-4f68-b946-c8f949ccfa3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "f1_test = f1_score(y_test, y_pred, average= 'weighted')\n",
        "\n",
        "print(\"Test set results\")\n",
        "print(\"ACCURACY ---------------------->\",acc_test)\n",
        "print(\"F1 SCORE ---------------------->\",f1_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results\n",
            "ACCURACY ----------------------> 0.9259259259259259\n",
            "F1 SCORE ----------------------> 0.9245135111801778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX084s0rP4NE",
        "colab_type": "text"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBNvtJoRP6N8",
        "colab_type": "code",
        "outputId": "9b6d7fb0-862a-4886-ee88-a0f45458f668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19  0  0]\n",
            " [ 0 11  3]\n",
            " [ 1  0 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_wgolayP-Yp",
        "colab_type": "text"
      },
      "source": [
        "Our decision Tree has done well in predicting our Train as well as Test set. So it has made the **appropriate fitting**\n",
        "\n",
        "Though, normal Random Forest works with greater accuracy in this case, it does not for all other cases. Hence for some datasets its important that we use Boosting Algorithms like Adaboost, XGboost etx..,\n"
      ]
    }
  ]
}